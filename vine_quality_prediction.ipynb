{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a005d1",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc65ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45906445db5c481fb553d6f4167d7663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col, count, when\n",
    "import numpy as np\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d8578",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec2d2746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5235e76e5250458bbdb06bd6467e4798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession created.\n",
      "+----------------------+------------------------+-------------------+----------------------+-----------------+---------------------------+----------------------------+---------------+----------+-----------------+---------------+----------------+\n",
      "|\"\"\"\"\"fixed acidity\"\"\"\"|\"\"\"\"volatile acidity\"\"\"\"|\"\"\"\"citric acid\"\"\"\"|\"\"\"\"residual sugar\"\"\"\"|\"\"\"\"chlorides\"\"\"\"|\"\"\"\"free sulfur dioxide\"\"\"\"|\"\"\"\"total sulfur dioxide\"\"\"\"|\"\"\"\"density\"\"\"\"|\"\"\"\"pH\"\"\"\"|\"\"\"\"sulphates\"\"\"\"|\"\"\"\"alcohol\"\"\"\"|\"\"\"\"quality\"\"\"\"\"|\n",
      "+----------------------+------------------------+-------------------+----------------------+-----------------+---------------------------+----------------------------+---------------+----------+-----------------+---------------+----------------+\n",
      "|                   8.9|                    0.22|               0.48|                   1.8|            0.077|                         29|                          60|         0.9968|      3.39|             0.53|            9.4|               6|\n",
      "|                   7.6|                    0.39|               0.31|                   2.3|            0.082|                         23|                          71|         0.9982|      3.52|             0.65|            9.7|               5|\n",
      "|                   7.9|                    0.43|               0.21|                   1.6|            0.106|                         10|                          37|         0.9966|      3.17|             0.91|            9.5|               5|\n",
      "|                   8.5|                    0.49|               0.11|                   2.3|            0.084|                          9|                          67|         0.9968|      3.17|             0.53|            9.4|               5|\n",
      "|                   6.9|                     0.4|               0.14|                   2.4|            0.085|                         21|                          40|         0.9968|      3.43|             0.63|            9.7|               6|\n",
      "|                   6.3|                    0.39|               0.16|                   1.4|             0.08|                         11|                          23|         0.9955|      3.34|             0.56|            9.3|               5|\n",
      "|                   7.6|                    0.41|               0.24|                   1.8|             0.08|                          4|                          11|         0.9962|      3.28|             0.59|            9.5|               5|\n",
      "|                   7.9|                    0.43|               0.21|                   1.6|            0.106|                         10|                          37|         0.9966|      3.17|             0.91|            9.5|               5|\n",
      "|                   7.1|                    0.71|                  0|                   1.9|             0.08|                         14|                          35|         0.9972|      3.47|             0.55|            9.4|               5|\n",
      "|                   7.8|                   0.645|                  0|                     2|            0.082|                          8|                          16|         0.9964|      3.38|             0.59|            9.8|               6|\n",
      "|                   6.7|                   0.675|               0.07|                   2.4|            0.089|                         17|                          82|         0.9958|      3.35|             0.54|           10.1|               5|\n",
      "|                   6.9|                   0.685|                  0|                   2.5|            0.105|                         22|                          37|         0.9966|      3.46|             0.57|           10.6|               6|\n",
      "|                   8.3|                   0.655|               0.12|                   2.3|            0.083|                         15|                         113|         0.9966|      3.17|             0.66|            9.8|               5|\n",
      "|                   6.9|                   0.605|               0.12|                  10.7|            0.073|                         40|                          83|         0.9993|      3.45|             0.52|            9.4|               6|\n",
      "|                   5.2|                    0.32|               0.25|                   1.8|            0.103|                         13|                          50|         0.9957|      3.38|             0.55|            9.2|               5|\n",
      "|                   7.8|                   0.645|                  0|                   5.5|            0.086|                          5|                          18|         0.9986|       3.4|             0.55|            9.6|               6|\n",
      "|                   7.8|                     0.6|               0.14|                   2.4|            0.086|                          3|                          15|         0.9975|      3.42|              0.6|           10.8|               6|\n",
      "|                   8.1|                    0.38|               0.28|                   2.1|            0.066|                         13|                          30|         0.9968|      3.23|             0.73|            9.7|               7|\n",
      "|                   5.7|                    1.13|               0.09|                   1.5|            0.172|                          7|                          19|          0.994|       3.5|             0.48|            9.8|               4|\n",
      "|                   7.3|                    0.45|               0.36|                   5.9|            0.074|                         12|                          87|         0.9978|      3.33|             0.83|           10.5|               5|\n",
      "+----------------------+------------------------+-------------------+----------------------+-----------------+---------------------------+----------------------------+---------------+----------+-----------------+---------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MLlibTraining\").getOrCreate()\n",
    "print(\"SparkSession created.\")\n",
    "s3_path_train = \"s3://vine-data/TrainingDataset.csv\"\n",
    "s3_path_val = \"s3://vine-data/ValidationDataset.csv\"\n",
    "s3_output_path = \"s3://vine-data/output_log.csv\"\n",
    "model_path = \"s3://vine-data/model\"\n",
    "df_train = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"quote\", \"\\\"\").csv(s3_path_train)\n",
    "df_val = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"quote\", \"\\\"\").csv(s3_path_val)\n",
    "df_train .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c890fc",
   "metadata": {},
   "source": [
    "create a SparkSession, read data from two CSV files located in Amazon S3, and display the content of the training dataset using the show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127da7b",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6414f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a4c96527ac41fea66f2179c6a9d4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------------+-------------------+----------------------+-----------------+---------------------------+----------------------------+---------------+----------+-----------------+---------------+----------------+\n",
      "|\"\"\"\"\"fixed acidity\"\"\"\"|\"\"\"\"volatile acidity\"\"\"\"|\"\"\"\"citric acid\"\"\"\"|\"\"\"\"residual sugar\"\"\"\"|\"\"\"\"chlorides\"\"\"\"|\"\"\"\"free sulfur dioxide\"\"\"\"|\"\"\"\"total sulfur dioxide\"\"\"\"|\"\"\"\"density\"\"\"\"|\"\"\"\"pH\"\"\"\"|\"\"\"\"sulphates\"\"\"\"|\"\"\"\"alcohol\"\"\"\"|\"\"\"\"quality\"\"\"\"\"|\n",
      "+----------------------+------------------------+-------------------+----------------------+-----------------+---------------------------+----------------------------+---------------+----------+-----------------+---------------+----------------+\n",
      "|                     0|                       0|                  0|                     0|                0|                          0|                           0|              0|         0|                0|              0|               0|\n",
      "+----------------------+------------------------+-------------------+----------------------+-----------------+---------------------------+----------------------------+---------------+----------+-----------------+---------------+----------------+"
     ]
    }
   ],
   "source": [
    "# Count the number of null values in each column\n",
    "null_counts = df_train.select([count(when(col(c).isNull(), c)).alias(c) for c in df_train.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a890ea",
   "metadata": {},
   "source": [
    "There are no null values. So no need to handle null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a081e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a416b550174b6db946a2ee20aa7a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col_name in df_train.columns:\n",
    "    df_train = df_train.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "for col_name in df_val.columns:\n",
    "    df_val = df_val.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "\n",
    "target_col = '\"\"\"\"quality\"\"\"\"\"'#Define the target variable\n",
    "\n",
    "(training_data, testing_data) = df_train, df_val# define training and testing sets\n",
    "\n",
    "feature_columns = df_train.columns[:-1]# Extract feature columns (exclude the target variable column)\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "training_data = assembler.transform(training_data)\n",
    "testing_data = assembler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e06a8f",
   "metadata": {},
   "source": [
    "**Data Type Conversion:**\n",
    "\n",
    "The first part of the code converts all the columns in df_train and df_val to the DoubleType() data type. This is done to ensure that all the columns have numerical values, which is a requirement for machine learning algorithms in Spark.\n",
    "\n",
    "**Define Target Variable:**\n",
    "\n",
    "The code defines the target variable's name as '\"\"\"\"quality\"\"\"\"\"'. This target variable is the variable we want to predict using machine learning models.\n",
    "\n",
    "**Training and Testing Sets:**\n",
    "\n",
    "The code then defines the training and testing datasets. It assigns the df_train to training_data and df_val to testing_data. These two DataFrames will be used for training and evaluating the machine learning models, respectively.\n",
    "\n",
    "**Feature Columns:**\n",
    "\n",
    "The code creates a list feature_columns, which includes all the columns in df_train except for the last one (last column is the target variable). These are the columns that will be used as features for the machine learning models.\n",
    "\n",
    "**Vector Assembler:**\n",
    "\n",
    "The VectorAssembler is used to combine the feature columns into a single vector column named \"features\". This is a required step in Spark MLlib as many algorithms expect the input features to be in a single vector column. The \"features\" column will be used as the input for the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c75df",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1956f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12895de9516a412ea19c737017e8e83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.4625\n",
      "Decision Tree Precision: 0.4708583959899749\n",
      "Decision Tree F1: 0.4657606075216971\n",
      "Decision Tree Recall : 0.4625\n",
      "\n",
      "Random Forest Accuracy: 0.48125\n",
      "Random Forest Precision: 0.46109611575704224\n",
      "Random Forest F1: 0.47068112976761034\n",
      "Random Forest Recall : 0.48124999999999996\n",
      "\n",
      "Logistic Regression Accuracy: 0.58125\n",
      "Logistic Regression Precision: 0.5488006876164772\n",
      "Logistic Regression F1: 0.5626444994918698\n",
      "Logistic Regression Recall : 0.58125"
     ]
    }
   ],
   "source": [
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "\n",
    "# Create a DecisionTreeClassifier instance\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=target_col)\n",
    "\n",
    "# Create a ParamGridBuilder with hyperparameters to tune\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(dt.maxBins, [32, 64, 128]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator with the DecisionTreeClassifier, evaluator, and paramGrid\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "crossval = CrossValidator(estimator=dt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)\n",
    "\n",
    "# Run cross-validation to find the best hyperparameters\n",
    "cvModel = crossval.fit(training_data)\n",
    "\n",
    "# Get the best Decision Tree model from cross-validation\n",
    "dt_model = cvModel.bestModel\n",
    "\n",
    "dt_predictions = dt_model.transform(testing_data)\n",
    "dt_accuracy = evaluator_accuracy.evaluate(dt_predictions)\n",
    "dt_f1 = evaluator_f1.evaluate(dt_predictions)\n",
    "dt_precision = evaluator_precision.evaluate(dt_predictions)\n",
    "dt_recall = evaluator_recall.evaluate(dt_predictions)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Decision Tree Precision:\", dt_precision)\n",
    "print(\"Decision Tree F1:\", dt_f1)\n",
    "print(\"Decision Tree Recall :\", dt_recall)\n",
    "print()\n",
    "\n",
    "# Create a RandomForestClassifier instance\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=target_col)\n",
    "\n",
    "# Create a ParamGridBuilder with hyperparameters to tune\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 150]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator with the RandomForestClassifier, evaluator, and paramGrid\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)\n",
    "\n",
    "# Run cross-validation to find the best hyperparameters\n",
    "cvModel = crossval.fit(training_data)\n",
    "\n",
    "# Get the best Random Forest model from cross-validation\n",
    "rf_model = cvModel.bestModel\n",
    "\n",
    "# Step 10: Evaluate the Random Forest model\n",
    "rf_predictions = rf_model.transform(testing_data)\n",
    "rf_accuracy = evaluator_accuracy.evaluate(rf_predictions)\n",
    "rf_f1 = evaluator_f1.evaluate(rf_predictions)\n",
    "rf_precision = evaluator_precision.evaluate(rf_predictions)\n",
    "rf_recall = evaluator_recall.evaluate(rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Precision:\", rf_precision)\n",
    "print(\"Random Forest F1:\", rf_f1)\n",
    "print(\"Random Forest Recall :\", rf_recall)\n",
    "print()                                   \n",
    "                                      \n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=target_col)\n",
    "\n",
    "# Create a ParamGridBuilder with hyperparameters to tune\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.3]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator with the LogisticRegression, evaluator, and paramGrid\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)\n",
    "\n",
    "# Run cross-validation to find the best hyperparameters\n",
    "cvModel = crossval.fit(training_data)\n",
    "\n",
    "# Get the best Logistic Regression model from cross-validation\n",
    "lr_model = cvModel.bestModel\n",
    "\n",
    "#Evaluate the Logistic Regression model\n",
    "lr_predictions = lr_model.transform(testing_data)\n",
    "lr_accuracy = evaluator_accuracy.evaluate(lr_predictions)\n",
    "lr_f1 = evaluator_f1.evaluate(lr_predictions)\n",
    "lr_precision = evaluator_precision.evaluate(lr_predictions)\n",
    "lr_recall = evaluator_recall.evaluate(lr_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression Precision:\", lr_precision)\n",
    "print(\"Logistic Regression F1:\", lr_f1)\n",
    "print(\"Logistic Regression Recall :\", lr_recall)\n",
    "print()                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8540401",
   "metadata": {},
   "source": [
    "perform multi-class classification with three different classifiers: Decision Tree Classifier, Random Forest Classifier, and Logistic Regression Classifier. The data has already been prepared with the appropriate feature vectors and target variable.Also, this performe hyperparameter tuning for the Decision Tree Classifier, Random Forest Classifier, and Logistic Regression Classifier using cross-validation with different hyperparameter values. It evaluates each model's performance on the testing data using accuracy, precision, F1 score, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83212add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cc9d82c49d45fc927c8ed9bf437620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values have been written to: s3://vine-data/output_log.csv"
     ]
    }
   ],
   "source": [
    "result_data = spark.createDataFrame([\n",
    "    (\"Decision Tree\", dt_accuracy, dt_precision, dt_f1, dt_recall),\n",
    "    (\"Random Forest\", rf_accuracy, rf_precision, rf_f1, rf_recall),\n",
    "    (\"Logistic Regression\", lr_accuracy, lr_precision, lr_f1, lr_recall)\n",
    "], [\"Model\", \"Accuracy\", \"Precision\", \"F1 Score\", \"Recall\"])\n",
    "\n",
    "\n",
    "# Save the DataFrame to the CSV file in the S3 bucket\n",
    "coalesced_df = result_data.coalesce(1)\n",
    "coalesced_df.write.csv(s3_output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "print(\"Values have been written to:\", s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734d0c3",
   "metadata": {},
   "source": [
    "creates a DataFrame named result_data containing the evaluation results (accuracy, precision, F1 score, and recall) for the three classifiers: Decision Tree, Random Forest, and Logistic Regression. It then saves this DataFrame as a CSV file in the specified S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af7da5",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ded531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22650d9108646b281a40750a94394f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression saved"
     ]
    }
   ],
   "source": [
    "max_=np.argmax(np.array((lr_accuracy,rf_accuracy,dt_accuracy)))\n",
    "if max_==0:\n",
    "    print('Logistic Regression saved')\n",
    "    lr_model.write().overwrite().save(model_path)\n",
    "elif max_==1:\n",
    "    print('Random Forest saved')\n",
    "    rf_model.write().overwrite().save(model_path)\n",
    "elif max_==2:\n",
    "    print('Decision Tree saved')\n",
    "    dt_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6606d7",
   "metadata": {},
   "source": [
    "determines which model (Logistic Regression, Random Forest, or Decision Tree) has the highest accuracy among the evaluated models and saves that best model to a specified path using the .save() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406f3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
